# Space Live Project 前端架構說明

## 整體資料流與狀態管理

Space Live 前端採用**單向資料流**的架構：資料從後端 API 或 WebSocket 進入，經由狀態管理儲存，再由元件消費與呈現。專案使用 **Zustand** 取代 Redux 或 Context 作為全域狀態管理工具[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/store/index.ts#:~:text=export%20const%20useStore%20%3D%20create)。各功能模組都有獨立的 **slice** 狀態（類似 Redux 切片），並在啟動時透過 `useStore` hook 合併為單一全域 Store[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/store/index.ts#:~:text=devtools)。這些 slice 定義在 `src/store/slices/` 資料夾下，例如 `chatSlice` 管理聊天訊息與處理狀態、`webSocketSlice` 管理 WebSocket 連線狀態等。

資料流過程如下：

- **資料來源**：應用程式啟動時即透過 WebSocket 與後端建立連線（由 WebSocketService 處理），同時也可根據需要透過 HTTP API 取得資料（由 api 模組提供）。例如聊天功能中，使用者發送訊息時會呼叫後端對話 API，後端回傳的聊天結果與相關資料（如語音音檔 URL、情緒軌跡等）則可能經由 WebSocket **推送**給前端。
- **狀態更新**：當後端回應資料時，對應的 service 會解析後端訊息並**更新全域狀態**。例如 ChatService 收到新的聊天消息時，會透過 `useStore.getState().setMessages(...)` 等方法更新聊天訊息列表[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=match%20at%20L1076%20useStore)[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=match%20at%20L1124%20useStore)。由於使用 Zustand，可以直接呼叫全域 store 的 setter 更新狀態。
- **UI 消費**：各 React 元件透過 custom hook（下節詳述）訂閱所需的狀態，React 會觸發重新渲染並將最新資料透過 props 或內部狀態展示給使用者。例如聊天視窗元件會透過 `useChatService()` 取得當前訊息列表與載入狀態，並渲染對話內容與「發送中...」提示[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=messages%2C%20%20%20%20,%3D%20useChatService)[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=%7Bmessages.map%28%28msg%2C%20index%29%20%3D%3E%20%28%20,setUserInput%28e.target.value)。

狀態管理方面，全域 store（Zustand）保存了應用各部分的核心狀態，如 UI 模式、載入/錯誤狀態等。例如 `appSlice` 定義了當前活動視圖 (`activeTab`)、是否進入除錯模式、全域載入/錯誤訊息等狀態[github.com](https://github.com/eggyy1224/space_live_project/raw/refs/heads/main/prototype/frontend/src/store/slices/appSlice.ts#:~:text=number%3B%20,message%3A%20string)[github.com](https://github.com/eggyy1224/space_live_project/raw/refs/heads/main/prototype/frontend/src/store/slices/appSlice.ts#:~:text=void%3B%20,...toast%2C%20id)。各 slice 也定義了修改這些狀態的 action 函式[github.com](https://github.com/eggyy1224/space_live_project/raw/refs/heads/main/prototype/frontend/src/store/slices/appSlice.ts#:~:text=%27prompt%27%20,)[github.com](https://github.com/eggyy1224/space_live_project/raw/refs/heads/main/prototype/frontend/src/store/slices/appSlice.ts#:~:text=%27prompt%27%2C%20audioDuration%3A%20null%2C%20%2F%2F%20%E6%93%8D%E4%BD%9C%E5%AF%A6%E7%8F%BE,%28%7B%20isSettingsPanelVisible)，供應用各處調用。由於 Zustand hook 可以直接讀取/設定狀態，不需要繁瑣的 action type 定義，讓資料流更直觀。

需要注意的是，**服務層**（services）在資料流中扮演控制器的角色，負責在資料來源與狀態更新/元件之間傳遞資料。使用者操作（例如點擊按鈕發送訊息、按下錄音鍵）首先調用對應的 service 函式，service 可能透過 API 或 WebSocket 與後端交互，再將結果寫入 store。元件本身則保持相對純粹，只透過訂閱 state 和調用 service 提供的函式來影響資料。這種分層確保**各層職責分離**：資料請求與業務邏輯在 service，狀態集中在 store，視圖更新在 component。

## 資料夾結構與模組職責

專案程式碼位於 `prototype/frontend/src/` 資料夾下，採用典型的分層模組化結構。各主要子資料夾的用途與層級分工如下：

- **components/**：主要存放 React 元件，包括 UI 介面和畫面組成部分。這裡的元件多為**視圖層**，不直接執行資料請求，而是透過 props 或 hooks 接收資料。`components/` 根目錄下包含一般元件，例如:
    - `BodyModel.tsx` 和 `HeadModel.tsx`：3D 模型元件，分別渲染太空人的身體和頭部模型。它們負責載入 GLTF 模型並繫結動畫或表情控制等。
    - `FloatingChatWindow.tsx`：浮動聊天視窗元件，包含聊天訊息列表和輸入框 UI，負責呈現聊天對話內容與提供使用者輸入介面。
    - `ModelViewer.tsx`：模型檢視器，將頭部、身體模型和場景組合起來呈現在畫面上（內部可能使用 Three.js 的 `<Canvas>` 建立3D場景）。
    - 其他如 `MorphTargetControls.tsx`（Morph target 表情控制滑桿），`SettingsPanel.tsx`（設定面板），`Toast.tsx`（提示訊息元件）等，對應不同的 UI 功能。
    
    此外，`components/layout/` 子資料夾定義了較高階的佈局元件，例如:
    
    - `AppUI.tsx`：整個應用的頂層 UI 布局元件，負責組合主要區塊（例如3D場景區與聊天區）並根據應用狀態決定哪個區塊顯示。
    - `SceneContainer.tsx`：場景容器，用於承載3D Canvas與環境設定，將3D模型置於特定版面中。
- **pages/**：由於本專案非使用 Next.js 路由架構，而是單頁應用（SPA），因此沒有獨立的 `pages/` 資料夾來定義多頁面路由。取而代之的是透過全域狀態 `activeTab` 來切換主要畫面（例如控制介面 vs 聊天介面）。不過，可以將應用的兩種主要模式（聊天模式與控制模式）概念上視為兩個「頁面」或視圖，由 `AppUI` 內根據 `activeTab` 切換呈現。例如當 `activeTab` 為 `'control'` 時，顯示模型控制面板；為 `'chat'` 時則顯示聊天視窗[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/components/layout/AppUI.tsx#:~:text=)。因此雖無傳統 pages 檔案，**元件結構已實現類似多頁切換的功能**。
- **hooks/**：自訂 React Hooks，封裝可重複使用的邏輯模組。一些複雜的狀態計算或副作用處理會放在這裡。例如唯一的 `useEmotionalSpeaking.ts` hook 提供「情緒化說話」的狀態管理，處理太空人說話時的情緒表現同步。這類 hook 不直接產生 UI，而是提供給元件使用，讓元件能方便取得特定狀態或行為。例如 `useEmotionalSpeaking` 內會根據後端提供的情緒軌跡資料計算當前的表情強度，元件可以每幀調用其提供的方法來更新模型表情。
- **services/**（相當於傳統的 *lib* 或 *controllers* 層）：封裝與後端溝通和裝置控制的**業務邏輯**。每個 service 模組都對應一項核心功能，內含一個類別和一個 React Hook。例如：
    - `WebSocketService.ts`：管理 WebSocket 連線。包含建立/關閉連線、發送與接收訊息等方法，以及供外部註冊訊息處理器的介面[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=%2F%2F%20%E5%B0%8E%E5%85%A5%E6%9C%8D%E5%8B%99%20import%20,services)。對應的 hook `useWebSocket` 可讓元件取得當前連線狀態及發送訊息函式等[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=function%20MyComponent%28%29%20,%3D%20useWebSocket)。
    - `AudioService.ts`：管理音訊錄製與播放。內部使用瀏覽器 Web Audio API 來錄音和產生音訊播放，並追蹤麥克風許可權狀態。透過 `useAudioService` hook，元件可得知是否正在錄音/播放，以及啟動錄音或播放語音的函式[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=function%20MyComponent%28%29%20,%2F%2F%20%E6%92%AD%E6%94%BE%E9%9F%B3%E9%A0%BB)。
    - `HeadService.ts` 與 `BodyService.ts`：管理3D頭部與身體模型的操作。由於太空人模型拆分為頭部與身體兩部分，這兩個 service 分別控制各自的狀態（例如頭部表情 morph 值、身體動畫等）。Hook 如 `useHeadService` 提供方法控制頭部表情（設定 morph target、重置表情等），`useBodyService` 提供方法控制身體姿態（旋轉、縮放模型等）。
    - `ChatService.ts`：管理聊天對話邏輯。負責維護聊天訊息列表、目前使用者輸入、以及與後端AI對話的交互。其內部透過 WebSocket 和 HTTP API 與後端溝通，在收到新訊息或回應時更新聊天狀態。`useChatService` hook 讓元件能取得目前消息列表、處理中的狀態旗標，以及呼叫發送訊息或清空對話等函式[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=messages%2C%20%20%20%20,%3D%20useChatService)[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=%7Bmessages.map%28%28msg%2C%20index%29%20%3D%3E%20%28%20,setUserInput%28e.target.value)。
    
    Service 資料夾中還有公用模組：
    
    - `api.ts`：封裝 HTTP 請求邏輯，包含預設的 API Base URL 組合以及通用 `fetchApi` 函式。各 service 可透過此模組統一地發送 HTTP 請求（如 POST/GET 後端介面）。
    - `audioPlayer.ts`：可能封裝音訊播放相關的輔助函式（例如建立 AudioContext，播放二進位音訊流等），供 AudioService 使用。
    - `index.ts`：集中匯出所有服務的 hook（如 `useWebSocket, useAudioService, useChatService` 等），方便各元件匯入使用。
    
    > Note: services 在程式架構中對應邏輯層/控制層，負責處理副作用（如網路、設備）並調用 store 更新狀態。這使得視圖元件可以保持簡潔，只專注於呈現資料。
    > 
- **utils/**：實用工具函式或類別，提供跨模組使用的功能，沒有直接的 React 相依性。例如:
    - `LogManager.ts`：日誌管理，用於輸出偵錯資訊或錯誤訊息，可能封裝 console.log 並根據環境控制輸出等。
    - `ModelAnalyzer.ts`：模型分析工具，對3D模型的結構或參數進行計算和轉換。例如提取模型的 morph target 名稱清單、分析動畫剪輯等，供模型元件或服務使用。
    - `animationUtils.ts`：動畫相關的工具函式，處理插值計算、時間軸換算等以支持模型動畫和表情過渡。
- **config/**：配置檔案，儲存常量設定或預設對照表。包括:
    - `animationConfig.ts`：定義模型動畫的設定值，例如動畫剪輯名稱、持續時間或播放模式預設值。
    - `emotionMappings.ts`：情緒對應表，將特定情緒標籤映射到頭部模型的基礎表情 morph target 權重值。這用於計算不同情緒下臉部各部分（眉毛、嘴型等）的變化程度。
    - `modelConfig.ts`：模型相關的配置，例如模型檔案路徑、初始縮放/位置、鏡頭參數等。
- **types/**：TypeScript 型別定義。定義全域使用的介面，例如聊天訊息物件結構、WebSocket 訊息結構、服務返回的狀態物件類型等。在程式中大量使用明確的型別讓介面清晰，例如 `AppSlice`、`ChatSlice` 等 interface 定義每個 slice state 的欄位與函式[github.com](https://github.com/eggyy1224/space_live_project/raw/refs/heads/main/prototype/frontend/src/store/slices/appSlice.ts#:~:text=number%3B%20,message%3A%20string)。types 資料夾確保型別集中管理，方便日後擴充或修改。

以上各層協同運作時，遵循**單一職責**原則：components專注於UI，services專注於邏輯，utils提供輔助函式，store集中狀態。清楚的資料夾結構讓後續開發者能快速定位功能所在位置，例如看到 UI 顯示問題，先檢查 components；數據沒更新，檢查 services 與 store。

## 主要元件與畫面功能說明

應用主要由兩大互動區域組成：**太空人直播畫面**（LiveRoom）和**聊天對話區**（ChatRoom）。此外，系統還包含控制面板和設定等子功能。以下說明各重要元件/畫面的責任與資料來源：

- **LiveRoom（直播互動區）**：此區域呈現虛擬太空人的3D即時影像和控制介面，可視為「直播間」。LiveRoom 的主要職責是顯示太空人模型並提供操控其動作/表情的介面。畫面上包含:
    - **3D模型與場景**：由 `ModelViewer`/`SceneContainer` 相關元件承載。它使用 React Three Fiber 將載入的太空人3D模型（頭部和身體）加載到 Canvas 中。模型的狀態（如是否載入完成、當前動畫、表情數值等）來自 `HeadService` 和 `BodyService`。例如頭部模型元件會透過 `useHeadService()` 取得目前 morph target 值和控制函式，用於更新面部表情；身體模型透過 `useBodyService` 取得可用動畫列表及目前播放的動畫等。
    - **控制介面**：當 LiveRoom 處於「控制模式」（activeTab = 'control'）時，會顯示各種控制元件，例如旋轉/縮放按鈕、動畫下拉選單、表情滑桿等。這些由 `SettingsPanel`、`MorphTargetControls` 等元件實現。它們透過 props 或 hook 與模型服務交互，例如點擊「向左旋轉」按鈕即調用 `rotateModel('left')` 函式旋轉模型[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=availableAnimations%2C%20%20%20%2F%2F%20%E5%8F%AF%E7%94%A8%E5%8B%95%E7%95%AB%E5%88%97%E8%A1%A8,%2F%2F%20%E9%87%8D%E7%BD%AE%E6%89%80%E6%9C%89Morph%20Target)[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=return%20%28%20,showSpaceBackground%20%3F%20%27%E9%9A%B1%E8%97%8F%E6%98%9F%E7%A9%BA%27%20%3A%20%27%E9%A1%AF%E7%A4%BA%E6%98%9F%E7%A9%BA)。所有這些操作最終會更新 store 中模型的狀態（如 `headSlice` 或 `bodySlice`），3D模型元件檢測到狀態改變後，就會執行對應變化（例如調整 morph target）。
    - **直播背景**：LiveRoom 也負責切換場景背景（如太空星空顯示與否）。透過模型服務提供的 `toggleBackground()` 函式可以開關背景星空[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=showSpaceBackground%2C%20%20%20%2F%2F%20%E6%98%AF%E5%90%A6%E9%A1%AF%E7%A4%BA%E5%A4%AA%E7%A9%BA%E8%83%8C%E6%99%AF,%2F%2F%20%E9%81%B8%E6%93%87%E5%8B%95%E7%95%AB)[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=,div)。背景設定存儲在全域狀態（如 `showSpaceBackground` 旗標），一旦改變會導致 Scene 元件重新渲染背景。
    - **音訊播放**：當後端傳回太空人語音時（例如透過文字轉語音的音檔 URL），LiveRoom 需要播放該音訊，使太空人「開口說話」。AudioService 會處理音訊載入和播放，並將 `isSpeaking` 狀態更新到 store[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=function%20MyComponent%28%29%20,%2F%2F%20%E6%92%AD%E6%94%BE%E9%9F%B3%E9%A0%BB)。3D頭部模型會監聽這個 `isSpeaking` 狀態和語音的口型數據，配合 `useEmotionalSpeaking` 計算出的情緒表情權重，即時調整嘴型動作，達成語音與嘴型同步。
- **ChatRoom（聊天對話區）**：此區域提供使用者與虛擬太空人互動對話的介面。主要由 `FloatingChatWindow` 元件實現一個懸浮在畫面上的聊天視窗。ChatRoom 的功能與資料如下:
    - **訊息列表**：顯示歷史對話訊息，包括使用者訊息和太空人的回覆。資料來源是 ChatService 管理的 `messages` 狀態列表[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=messages%2C%20%20%20%20,%3D%20useChatService)。每則訊息包含角色（user or assistant）及文字內容等。FloatingChatWindow 透過 `useChatService()` 取得 `messages` 陣列並 render 列表項目。
    - **輸入框與發送**：提供文字輸入欄位和發送按鈕，讓使用者輸入問題。`useChatService` 裡維護了當前使用者輸入 `userInput` 狀態及更新函式 `setUserInput`[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=messages%2C%20%20%20%20,%2F%2F%20%E7%99%BC%E9%80%81%E6%B6%88%E6%81%AF)[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=,div)。使用者輸入文字後按下發送，會觸發 ChatService 的 `sendMessage()`[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=setUserInput%2C%20%20%20%20,%3D%20useChatService)[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=,div)，該函式負責將使用者輸入送往後端 API。此時 ChatService 會先將使用者訊息加入本地 messages 列表以即時顯示，並將對話狀態 `isProcessing` 設為 true 以指示等待回覆[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=match%20at%20L1124%20useStore)[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=useStore)。
    - **載入與狀態提示**：當等待太空人回覆時，ChatRoom 會顯示處理中的提示（例如「AI正在思考...」）。這透過 ChatService 的 `isProcessing` 狀態控制。元件從 `useChatService` 獲取 `isProcessing` 布林值，若為 true 則可能在UI上禁用輸入或顯示 loading spinner。收到回覆後 ChatService 將 `isProcessing` 設回 false[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=match%20at%20L1088%20useStore)，UI 隨即解除載入狀態。
    - **情緒表現**：太空人的回覆不僅包含文字，還可能帶有情緒資訊（例如後端分析出回覆語氣是開心、驚訝等）。ChatService 在接收後端回覆時，會同時更新一個 `emotion` 狀態（可能存於 chatSlice），表示當前對話情緒。該情緒會影響太空人的表情呈現：`useEmotionalSpeaking` hook 和 HeadService 共同作用，根據情緒設定對應的臉部表情。例如當 emotion 狀態變為 "happy"，head 模型會調高笑容的 morph target。這樣使用者在 ChatRoom 不僅能看到文字回覆，還能**透過 LiveRoom 看到太空人對應的表情反應**，增強互動沉浸感。
- **LiveStream（即時串流顯示）**：在本專案語境下，LiveStream 可理解為太空人影像和聲音的**即時輸出**功能。它未必是一個獨立頁面，而是貫穿於 LiveRoom/ChatRoom 中的實時內容。例如:
    - **視覺串流**：透過 LiveRoom 的3D畫面，太空人模型的所有動作與表情變化即時呈現，類似於直播串流畫面。若將來需要將此畫面推送到真正的串流平台，可能會在 LiveStream 模組實現該功能。目前 LiveRoom 本身已實現畫面的即時更新，可視為 LiveStream 的視覺部分。
    - **音訊串流**：AudioService 負責將後端的語音回覆播放出來，這也是串流的一部分。當 ChatService 獲得語音音檔 URL（透過後端的 TTS 服務）時，會通知 AudioService 播放。AudioService 將音訊播放狀態 `isSpeaking` 設為 true，並可能觸發 `audioLipsyncTargets`（嘴型同步數據）更新到 store。HeadModel 監看這些狀態，透過每幀的 `useFrame` 回呼將嘴部相關 morph target 權重朝向目標值變化，以呈現逼真的口型同步[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/components/HeadModel.tsx#:~:text=const%20audioLipsyncTargetsFromStore%20%3D%20useStore%28%28state%29%20%3D,audioLipsyncTargets)[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/components/HeadModel.tsx#:~:text=useEffect%28%28%29%20%3D)。
    - **整合**：LiveStream 可以被視為將上述視覺與音訊同步組合成的**整體效果**。當太空人在回應時，使用者同時在 ChatRoom 看見文字，在 LiveRoom（LiveStream畫面）聽見聲音並看到太空人表情動作。所有這些同步都經由全域狀態協調：例如 ChatService 收到回覆後，同時更新 messages、emotion 和觸發 AudioService 去抓取播放音檔；AudioService播放時更新 isSpeaking；HeadService 透過 useEmotionalSpeaking 得知當前情緒軌跡計算表情[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/hooks/useEmotionalSpeaking.ts#:~:text=,emotion%20weights%20based%20on%20time)[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/hooks/useEmotionalSpeaking.ts#:~:text=const%20%5BcurrentTrajectory%2C%20setCurrentTrajectory%5D%20%3D%20useState,null)；HeadModel 在 useFrame 中調用 `calculateCurrentTrajectoryWeights()` 獲取當前時間點的情緒表情權重[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/components/HeadModel.tsx#:~:text=import%20,%E5%B0%8E%E5%85%A5%E6%96%B0%E7%9A%84%20Hook)[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/components/HeadModel.tsx#:~:text=const%20,useEmotionalSpeaking)，再融合語音口型和使用者手動設定的表情，最終套用到模型 morphTargetInfluences 上[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/components/HeadModel.tsx#:~:text=const%20manualOrPresetTargetsFromStore%20%3D%20useStore%28%28state%29%20%3D,morphTargets)[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/components/HeadModel.tsx#:~:text=%2F%2F%20)。這樣每一幀都根據最新狀態計算出最終的表情權重組合並渲染，達成影音同步的即時串流體驗。
- **其他介面**：除了上述主要區塊，應用還有一些輔助畫面/元件：
    - **設定面板**：點擊介面上的設定按鈕會打開 `SettingsPanel`（通常在控制模式下使用）。這顯示一些全域的開關，例如 Debug模式切換、攝影機遠近切換等。對應的狀態在 AppSlice 中（如 `isDebugMode`, `isCameraFar`），透過 SettingsPanel 更改時會更新全域狀態，進而影響整個應用（例如 DebugMode 開啟時顯示額外的模型資訊面板）。
    - **錯誤邊界**：`ErrorBoundary.tsx` 元件作為React錯誤邊界，包裹主要UI以攔截潛在的JS錯誤，避免整個應用崩潰，並顯示友好的錯誤提示。
    - **提示訊息**：`Toast.tsx` 元件用於短暫提示通知，例如操作成功或錯誤警告。AppSlice 提供了 `toasts` 狀態列表及操作方法 `addToast/removeToast`[github.com](https://github.com/eggyy1224/space_live_project/raw/refs/heads/main/prototype/frontend/src/store/slices/appSlice.ts#:~:text=%27prompt%27%20,)[github.com](https://github.com/eggyy1224/space_live_project/raw/refs/heads/main/prototype/frontend/src/store/slices/appSlice.ts#:~:text=%7D%29%29%2C%20setCameraDistance%3A%20%28isFar%29%20%3D,errorMessage%3A%20message)。各服務在適當時機（如出現錯誤或完成某任務）可呼叫 `addToast` 將消息加入，Toast 元件則訂閱 `toasts` 狀態並渲染出現一定時間的通知。

總之，各元件各司其職又彼此配合：**ChatRoom** 專注文字互動，**LiveRoom** 呈現視覺互動，兩者通過全域狀態同步，形成完整的使用者體驗（LiveStream效果）。開發者在維護時，可以快速定位相關元件：聊天問題查看 ChatRoom 實作，模型顯示問題查看 LiveRoom 相關元件及 ModelService 實作。

## 重要 Hooks 設計邏輯與使用方式

專案定義了多個自訂 Hooks 來封裝複雜邏輯，使元件使用更方便且保持簡潔。以下介紹幾個重要的 hooks 及其內部設計：

- **useWebSocket**（來自 WebSocketService）：用於管理 WebSocket 連線的 Hook。調用 `useWebSocket()` 會在元件中建立或取得全域唯一的 WebSocket 連線實例。它回傳當前連線狀態和若干操作方法，例如 `isConnected` 表示連線是否建立，`sendMessage(content)` 用於發送訊息，`sendTextMessage(text)` 快捷發送聊天文本，`registerHandler(event, handler)` 可註冊對某類型訊息的監聽處理函式[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=%2F%2F%20%E5%B0%8E%E5%85%A5%E6%9C%8D%E5%8B%99%20import%20,services)。Hook 實現時，一開始會嘗試建立 WebSocket 並監聽其 `onopen/onmessage/onerror/onclose` 事件，對於每個接收的訊息，尋找對應 event 名稱已註冊的 handler 加以處理。當元件 unmount 或不再需要時，可呼叫 `removeHandler` 解註冊處理器，避免內存洩漏。由於 WebSocketService 封裝為單例類別，useWebSocket 可確保**全應用共享同一連線**，各處註冊的 handler 也作用在同一通道上。
- **useAudioService**（來自 AudioService）：管理錄音與播音的 Hook。呼叫後返回關於麥克風和音訊播放的狀態與方法[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=function%20MyComponent%28%29%20,%2F%2F%20%E6%92%AD%E6%94%BE%E9%9F%B3%E9%A0%BB)：
    - 狀態值例如 `isRecording`（是否正在錄音）、`isSpeaking`（是否正在播放語音回覆）、`micPermission`（麥克風權限狀態）等，方便元件控制 UI 顯示。如錄音時可以顯示「錄音中...」提示[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=,div%3E)。
    - 操作方法包括 `startRecording()` 開始錄音、`stopRecording()` 停止錄音並將音檔送交後端進行語音識別、`playAudio(buffer)` 播放指定音訊緩衝等。AudioService 內部利用 Web Audio API，`startRecording` 會透過 MediaStream API 獲取麥克風輸入並開始錄製，同時將狀態 `isRecording` 設為 true；`stopRecording` 則結束錄音並將音訊資料發送到後端（可能使用 `api.ts` 的 `/api/speech-to-text` 端點）取得文字，再交由 ChatService 繼續對話流程。此外，AudioService 也會在初始化時檢查麥克風許可權，如果未授權可能更新 `micPermission` 為 `'denied'` 以供 UI 提示用戶授權。
    - 使用方式：任一元件（例如有一個錄音按鈕的元件）`const { isRecording, startRecording, stopRecording } = useAudioService();`，即可使用這些狀態控制按鈕樣式並綁定事件。在實際 UI 中，開發者常將按鈕的 onMouseDown 事件設為 `startRecording`，onMouseUp 設為 `stopRecording`[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=,div%3E)，實現按住錄音、鬆開發送的體驗。
- **useChatService**（來自 ChatService）：負責聊天對話的 Hook。這是應用的核心之一，返回聊天功能所需的所有狀態與操作[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=messages%2C%20%20%20%20,%3D%20useChatService)：
    - **狀態**：`messages`（訊息列表）、`userInput`（當前輸入框的內容）、`isProcessing`（AI回覆處理中狀態）、`emotion`（AI回覆的情緒標籤）等。其中 `messages` 為陣列，包含歷史對話記錄；`isProcessing` 為 true 時表示等待AI回應，此時元件可禁用發送操作並提示載入；`emotion` 表示最後一則AI訊息的情緒，例如 `'happy'`、`'sad'` 等，供其它部分（如表情）使用。
    - **方法**：`sendMessage()` 發送當前輸入內容給後端，`setUserInput(text)` 更新輸入框內容，`clearMessages()` 清空對話記錄等[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=messages%2C%20%20%20%20,%3D%20useChatService)[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=,div)。當使用者透過 UI 觸發 `sendMessage` 時，Hook 內部會先將當前 `userInput` 內容推入 messages 陣列作為使用者消息，接著呼叫 ChatService 類別實例的方法與後端通訊。ChatService 可能透過 HTTP 請求將使用者訊息傳給 AI 模型服務，或經由 WebSocket 發送（具體實作視後端API而定）。在等待過程中，Hook 將 `isProcessing` 設為 true。當後端回覆抵達（例如 WebSocket 收到 `'chat-message'` 事件[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=this.websocket.registerHandler%28%27chat)），ChatService 會將AI回覆消息加到 messages 並更新 `emotion` 狀態，隨後 Hook 把 `isProcessing` 設為 false，通知元件可以繼續下一次互動。
    - **設計邏輯**：ChatService 用類別實現單例，內含 WebSocket handler 註冊邏輯[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=this.websocket.registerHandler%28%27chat)[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=this.websocket.registerHandler%28%27error%27%2C%20%28data%3A%20any%29%20%3D)和發送/接收處理。例如在建構時向 WebSocketService 註冊監聽 `'chat-message'` 事件，一旦有AI新消息，就自動更新 store 中的 messages。Hook 在初次使用時會透過 ChatService 的靜態方法取得單例實例（如 `ChatService.getInstance()`），確保所有元件共享同一對話狀態，不會重複建立連線或註冊事件。總體而言，useChatService 將 **對話狀態** 與 **UI事件** 有效解耦：UI 不需要知道訊息如何傳遞，只透過 Hook 提供的方法發出請求、透過狀態取得結果。
- **useHeadService / useBodyService**：這兩個 Hook 提供對3D模型的操作介面。由於太空人模型拆分為頭和身體部分，相應的 service 也拆開。它們的設計類似，以下統稱描述：
    - **狀態**：如 `modelLoaded`（模型是否載入完成）、`availableAnimations`（可用動畫清單，主要在 BodyService）、`currentAnimation`（當前播放動畫）、`morphTargets`（頭部模型的各表情參數數值，主要在 HeadService）等[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=modelLoaded%2C%20%20%20%20,%2F%2F%20%E7%B8%AE%E6%94%BE%E6%A8%A1%E5%9E%8B)。HeadService 可能還管理如睜眼閉眼、張嘴等 morph target 值或預設表情組合。
    - **方法**：`rotateModel(direction)` 旋轉模型[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=availableAnimations%2C%20%20%20%2F%2F%20%E5%8F%AF%E7%94%A8%E5%8B%95%E7%95%AB%E5%88%97%E8%A1%A8,%2F%2F%20%E9%87%8D%E7%BD%AE%E6%89%80%E6%9C%89Morph%20Target)、`scaleModel(delta)` 縮放模型、`resetModel()` 重置模型位置/角度[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=rotateModel%2C%20%20%20%20,%3D%20useModelService)、`selectAnimation(name)` 選擇播放指定動畫、`updateMorphTargetInfluence(name, value)` 更新某個表情參數的權重、`applyPresetExpression(preset)` 應用預設表情等。這些函式封裝了對 Three.js 模型物件的操作。例如 rotateModel 內部其實是改變 store 中保存的 rotation 狀態，進而由 Model 元件的 useFrame 去讀取該狀態並對 3D 物件施加旋轉。
    - **Hook 運作**：當元件（如控制面板）使用 `const {rotateModel, morphTargets} = useHeadService();` 後，即可獲取表情控制相關狀態和修改函式。Hook 在初次執行時會透過 HeadService 類別載入3D頭部模型（通常使用 Three.js 的 GLTFLoader），載入完成後呼叫 `setHeadModelLoaded(true)` 更新狀態，以通知 App 可以開始互動。BodyService 類似地載入身體模型和動畫剪輯。一旦模型載入，Hook 會將模型物件引用存入 store 或 service，以便後續控制函式操作。例如 `selectAnimation` 會透過已載入的 AnimationMixer 播放對應名稱的動畫。由於所有這些狀態也存於 Zustand，全域的其他部分也可以監聽。例如 `appSlice` 中可能有 `currentAction` 狀態來表示目前使用者正在對模型做的操作（旋轉/縮放），以用於UI提示或禁止同時進行其他操作。
- **useEmotionalSpeaking**：這是專案中特色的自訂 hook，用於在太空人說話時控制其情緒表現的變化。它結合了聊天模組的情緒資料與3D頭部模型的表情控制：
    - **輸入來源**：主要依賴 WebSocket 從後端收到的一種特殊消息類型，稱為 “emotionalTrajectory”。這通常是後端為使虛擬角色表情更豐富所提供的**情緒軌跡**資料，即在接下來的若干秒內角色情緒如何隨時間變化的序列。例如太空人的回覆語音在3秒內從驚訝逐漸過渡到微笑，那後端會傳一組時間節點及對應情緒的列表。
    - **資料處理**：useEmotionalSpeaking Hook 內部會註冊監聽最新的 WebSocket 訊息或 ChatService 狀態，特別關注是否出現 `lastMessage.type === 'emotionalTrajectory'`[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/hooks/useEmotionalSpeaking.ts#:~:text=logger.debug%28%27,stringify%28lastMessage)。當偵測到新的情緒軌跡資料時，Hook 會解析其 payload，儲存為 `currentTrajectory` 狀態，並將一個**本地參考時間**記為軌跡起始。接著 Hook 利用 `emotionMappings` 中的對照表，準備計算每個時間點對應的表情 morph target 權重。
    - **回傳控制**：Hook 回傳一個物件，其中關鍵是 `calculateCurrentTrajectoryWeights(currentTime)` 函式。3D頭部模型元件每次渲染幀時都會呼叫此函式（通常在 R3F 的 `useFrame` 中進行[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/components/HeadModel.tsx#:~:text=useFrame%28%28state%2C%20delta%29%20%3D)），傳入當前的時間或增量，讓 Hook 根據 `currentTrajectory` 計算此刻的表情權重。內部邏輯通常是：找到軌跡中離當前時間最近的兩個關鍵影格 (emotion keyframes)，按時間插值計算出各情緒參數的當前值。例如 1秒時開心權重0.2，3秒時開心權重0.8，那在2秒時計算得開心權重約0.5。計算出的情緒權重集會返回給元件使用。
    - **結合應用**：HeadModel 元件取得這些權重後，會將其與其它表情來源合併（如使用者手動設定的表情值 `manualOrPresetTargets`、語音口型同步值 `audioLipsyncTargets`[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/components/HeadModel.tsx#:~:text=const%20manualOrPresetTargetsFromStore%20%3D%20useStore%28%28state%29%20%3D,morphTargets)[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/components/HeadModel.tsx#:~:text=%2F%2F%20)）。合併邏輯在 HeadModel 的 `useFrame` 中實現[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/components/HeadModel.tsx#:~:text=%2F%2F%20)：若當前正在播放語音 (`isSpeaking` 為 true)，則優先應用語音口型的下巴動作morph值，同時逐漸套用 emotionalTrajectory 計算的眉眼表情變化；若沒有語音，則完全按照 emotionalTrajectory 來。最終得到一組最終 morphTargets 權重後，設置給模型的 `mesh.morphTargetInfluences`。這樣就實現了角色表情隨對話語氣變化的動態演出。從開發角度看，useEmotionalSpeaking **將複雜的時間序列計算封裝**起來，元件只需每幀調用即可獲取結果，大幅降低了元件代碼負擔。

上述 Hooks 的使用方式都相對一致：在函式型元件中呼叫對應的 hook，解構出需要的狀態與方法，接著在 JSX 中利用這些狀態渲染 UI、將方法綁定到事件。這些 Hook 隱藏了與後端通訊、裝置控制、時間序列計算等細節，使開發者更關注於**資料如何呈現**而非資料從何而來。如 README 範例所示，開發者可以很直觀地寫出如下代碼使用這些 Hook：

```tsx
tsx
CopyEdit
const { messages, isProcessing, userInput, setUserInput, sendMessage } = useChatService();
...
{messages.map(msg => <div className={`message ${msg.role}`}>{msg.content}</div>)}
<input value={userInput} onChange={e => setUserInput(e.target.value)} />
<button onClick={sendMessage} disabled={isProcessing}>發送</button>

```

[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=%3Cdiv%3E%20%3Cdiv%20className%3D,input)[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=value%3D%7BuserInput%7D%20onChange%3D%7B%28e%29%20%3D,div)

經由自訂 Hook，聊天元件無需知曉消息是從何處來、如何處理，只需調用 hook 提供的方法，極大提高了模組解耦性。

## 資料請求與 API 管理

前端與後端溝通主要通過兩種方式：**HTTP API 請求** 和 **WebSocket 即時通訊**。專案採用了集中管理的策略來處理 API 呼叫以及統一錯誤與加載狀態：

- **HTTP 請求集中管理**：`src/services/api.ts` 定義了通用的 `fetchApi` 函式來封裝 HTTP 請求。它會自動將相對路徑的請求加上基底 URL（預設為本地開發伺服器，例如 `http://localhost:8000`[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=const%20API_BASE_URL%20%3D%20%60http%3A%2F%2F%24)），並統一處理錯誤。專案將後端各項服務的端點定義為函式，例如 `fetchApi('/api/analyze_text', {...})` 用於發送聊天文字讓後端分析[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/api.ts#:~:text=return%20fetchApi%28%27%2Fapi%2Fanalyze_text%27%2C%20)；`fetchApi('/api/text_to_speech', {...})` 用於請求將文字轉為語音[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/api.ts#:~:text=match%20at%20L939%20return%20fetchApi,)；`fetchApi('/api/speech-to-text', {...})` 用於上傳錄音並取得識別文字[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/api.ts#:~:text=match%20at%20L967%20return%20fetchApi%28%27%2Fapi%2Fspeech,)等。這些函式由 service 層的對應方法呼叫，使**所有 HTTP 請求經由單一模組調用**。好處是：
    - 可以在此統一攔截/處理錯誤狀況。例如如果任一請求返回非200狀態，`fetchApi` 可擲出錯誤或記錄，然後由調用處去捕捉。在 ChatService 等處理錯誤時，可使用全域錯誤狀態或 toast 呈現。
    - 減少重複代碼。每個請求都自帶 Base URL、headers 設定，在 fetchApi 中配置一次即可，無需每次書寫。
    對於**錯誤處理**，應用定義了 `AppSlice` 中的 `errorMessage` 狀態和對應 `setError` 方法[github.com](https://github.com/eggyy1224/space_live_project/raw/refs/heads/main/prototype/frontend/src/store/slices/appSlice.ts#:~:text=isSettingsPanelVisible%3A%20boolean%3B%20isLoading%3A%20boolean%3B%20errorMessage%3A,permission%3A%20%27prompt%27)[github.com](https://github.com/eggyy1224/space_live_project/raw/refs/heads/main/prototype/frontend/src/store/slices/appSlice.ts#:~:text=toast.id%20%21%3D%3D%20id%29%20,audioDuration%3A%20duration%20%7D%29%2C)。服務在 catch 到錯誤（例如後端500錯）時，可呼叫 `useStore.getState().setError("一些錯誤訊息")` 將錯誤訊息保存。UI 層可以有監聽此狀態的錯誤提示元件（如一個全域 <Toast>），一旦有錯誤訊息就彈出提示。此專案提供了 `Toast.tsx` 元件及 AppSlice 的 `toasts` 列表來顯示通知，因此更建議服務直接使用 `addToast({message, type: 'error'})`[github.com](https://github.com/eggyy1224/space_live_project/raw/refs/heads/main/prototype/frontend/src/store/slices/appSlice.ts#:~:text=%27prompt%27%20,)[github.com](https://github.com/eggyy1224/space_live_project/raw/refs/heads/main/prototype/frontend/src/store/slices/appSlice.ts#:~:text=%7D%29%29%2C%20setCameraDistance%3A%20%28isFar%29%20%3D,errorMessage%3A%20message)來彈出錯誤，不干擾主要流程狀態。
- **WebSocket 即時資料處理**：專案運用了 WebSocket 來處理即時互動需求，例如及時獲取 AI 回覆、表情軌跡和聊天室歷史等[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=this.websocket.registerHandler%28%27chat)。WebSocketService 通過 `registerHandler(eventType, handler)` 機制將不同服務的處理邏輯註冊給不同的消息類型。例如 ChatService 啟動時會向 WebSocketService 註冊：
    - `chat-message` 事件 -> 更新聊天訊息[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=this.websocket.registerHandler%28%27chat)
    - `chat-history` 事件 -> 加載歷史對話記錄[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=match%20at%20L1062%20this.websocket.registerHandler%28%27chat,)
    - `error` 事件 -> 處理錯誤通知[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=this.websocket.registerHandler%28%27error%27%2C%20%28data%3A%20any%29%20%3D)
    - 以及 `emotionalTrajectory` 這類表情軌跡事件 -> 交由 useEmotionalSpeaking 處理。
    
    WebSocketService 接收到伺服器發來的 JSON 時，根據其中的 `type` 欄位將 payload 分發給相應 handler 執行。這種集中式管理讓**訊息處理邏輯清晰可查**：所有 event->handler 綁定都定義在各自 Service 中，開發者能快速定位某類消息的處理方式。若未來增加新即時事件，只需在適當的 Service 中 `registerHandler` 即可，保持擴展性。
    
    **請求觸發**方面，WebSocketService 提供的 `sendMessage` 和 `sendTextMessage` 方法[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=function%20MyComponent%28%29%20,%3D%20useWebSocket)讓其他服務或元件可發送訊息到 WebSocket。例如 ChatService 的 `sendMessage()` 在將使用者輸入添加到本地 messages 後，就會呼叫 `useWebSocket().sendTextMessage(userInput)` 將文字發給伺服器，然後伺服器經過處理後再透過 `chat-message` 推送回結果。這比起反覆輪詢 REST API 有更低延遲與資源耗用，確保聊天對話體驗流暢。
    
- **狀態中的載入與錯誤指示**：為了讓 UI 即時反映資料請求狀態，專案在多處設置了「載入中」與「錯誤」狀態：
    - **全域載入**：AppSlice 的 `isLoading` 可以用來表示全域性的大場景載入（例如首次載入3D模型時）。元件可以根據它顯示整頁的 Loading spinner 或 Skeleton UI。
    - **局部載入**：針對不同 slice，也有獨立的處理中狀態。例如 ChatSlice 有 `isProcessing` 代表對話進行中[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=messages%2C%20%20%20%20,%3D%20useChatService)、AudioSlice（如果有的話）可能有 `isProcessingAudio` 等。這樣**互不影響**：播放音訊時不會阻塞UI其它部分的操作，而在等待AI回覆時可以僅禁用聊天輸入。
    - **錯誤**：除了全域的 `errorMessage` 外，各 service 在自己的狀態裡往往也有錯誤標記。例如 WebSocketSlice 可能有 `isConnected` 和 `lastError`，ChatSlice 可能有 `error` 來存儲最近一次對話請求錯誤。UI 可以選擇性地使用這些錯誤資訊。例如若 AI 回覆失敗，ChatRoom 可以在 messages 列表中加入一條「系統：發生錯誤，請稍後重試」的訊息，或觸發 Toast 通知。
    
    **錯誤恢復**：ErrorBoundary 元件會捕獲 React 渲染階段的錯誤，但對於資料請求錯誤，服務層通常能自行捕捉並處理，不會讓錯誤冒泡至整個應用崩潰。例如在 ChatService 發送請求時用 try-catch 包裹，catch 到錯誤時除了記錄日誌[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/services/ChatService.ts#:~:text=this.websocket.registerHandler%28%27error%27%2C%20%28data%3A%20any%29%20%3D)，還可能呼叫 `addToast` 顯示簡短錯誤。這樣使用者即便遇到後端故障，介面仍可繼續操作（例如再嘗試發送一次）。
    

綜上，專案的 API 管理由 **api.ts + WebSocketService** 共同構成：前者管HTTP請求，後者管長連線消息，都提供統一的介面給其他模組呼叫。在實作上，此架構達到了關注點分離——各服務模組不直接使用 `fetch` 或 `WebSocket` 實例，而是透過中介模組發送請求或註冊回調，減少重複代碼並提高可維護性。對開發者而言，要發一個 API 請求，只需調 `fetchApi(url, options)`；要監聽一個事件，只需調 `registerHandler(event, fn)`。這種統一的**集中管理**方式使得錯誤處理、日誌和權限控制都可在單處修改，提升系統健壯性。

## 最佳實踐與開發建議

針對目前的專案架構和實作，以下提供一些維護與擴充方面的最佳實踐與建議，供後續開發者參考：

1. **保持元件輕量，善用 Hooks 分擔邏輯**：目前元件透過自訂 hooks 獲取資料，使大部分狀態計算與副作用被隔離在 service 中。這樣的模式應當繼續遵循。當新增新功能時，建議**遵照現有模式**：將邏輯寫在 service（或新增新的 service），由 service 更新狀態，再通過 hook 提供給元件使用。避免在元件中直接使用 `useStore` 操作全域狀態，統一由 service 層封裝狀態變化。一來保持元件的簡潔，二來方便測試與重用這些邏輯。
2. **元件拆分與重構**：隨著功能增加，一些元件可能變得較為龐大（例如目前 `FloatingChatWindow.tsx` 和 `WebSocketService.ts` 檔案行數較多）。未來維護時，可以考慮**拆分**：
    - UI 元件可按照職責進一步拆分成更小的可重用元件。例如聊天視窗可拆成 `MessageList` 子元件（純呈現列表）和 `MessageInput` 子元件（處理輸入框和按鈕）。這樣一來，ChatWindow 的 render 函式會更精簡，也方便獨立調整樣式或邏輯。
    - 3D 模型相關的元件，也可依照功能區分子元件。例如表情控制區和動畫控制區可以是獨立元件，由 `ControlPanel` 整合。事實上，AppUI 中已經根據 activeTab 切換控制面板和聊天面板，我們可以進一步將 `ControlPanel` 獨立成一個檔案，包含 SettingsPanel、MorphTargetControls 等的組合，讓結構更清晰。
    - Service 類別檔案龐大時，可以適當將某些邏輯拆成 **utils 函式** 或 **協助類**。例如 WebSocketService 內如果有大量不同事件的處理程式，可以考慮將每類事件的處理函式獨立為文件或模組（如 chat 對應 chatHandlers.ts），在 WebSocket 接收消息時調用對應的處理函式組，這樣 WebSocketService 類本身只聚焦於連線管理。
3. **Prop 設計與資料流向**：維持元件之間明確的資料傳遞界面。盡量透過 props 向子元件傳遞所需資料或回呼，而非讓子元件自行訪問全域狀態。這在大部分情況下已透過 hooks 完成，但是例如 Toast 通知這類跨層級的元件，可以使用全域狀態或 context 無可厚非。未來若有類似需要全域訪問的 UI（如主題切換、使用者登入資訊等），可考慮使用 React Context 提供，或沿用 Zustand 全域 store。在prop設計上，建議**只傳遞元件必要的資料**，多餘的上下文不暴露，保持元件的通用性。例如 MessageList 只需收到 messages 陣列和也許一個 onScroll 底部事件，而不需要整個 ChatService 實例。這樣元件更易於重用或獨立測試。
4. **狀態結構擴展**：目前全域狀態以 slice 劃分，清晰明瞭。新增功能時，請根據領域在對應 slice 添加狀態，而不要產生跨領域的高度耦合狀態。例如將來加入「任務系統」，可新增 TaskSlice 管理任務列表與進度。Zustand 容易擴充 slices[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/store/index.ts#:~:text=%2F%2F%20%E5%90%88%E4%BD%B5%E6%89%80%E6%9C%89%20slice%20%E9%A1%9E%E5%9E%8B%E7%82%BA%E6%9C%80%E7%B5%82%20Store,%E9%A1%9E%E5%9E%8B)[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/store/index.ts#:~:text=devtools)，但仍須注意不要讓單一 slice 過於龐大。儘量遵循**單一來源真相**原則，每個資料只在一處 slice 維護，避免不同 slice 出現重複的欄位導致不同步問題。如果發現某些狀態需由多處共享又不屬於既有 slice，考慮獨立成新 slice 或歸入 AppSlice 作為全域雜項狀態，並在註釋中標明用途。
5. **持續使用 TypeScript 與介面**：程式碼中已廣泛使用 TypeScript 定義 state 和 message 等介面，這對維護十分有利。建議未來**所有新增的狀態與函式**都先定義類型。例如新加入一個「任務Task」物件時，在 `src/types/` 裡定義其 Interface，並在 store slice 和 service 中引用。保持型別定義集中能讓大家清楚各資料結構，也降低出錯機率。
6. **錯誤處理與使用者提示**：目前錯誤處理機制已經考慮使用 Toast 等提示。後續開發者應統一錯誤處理策略，例如：對於致命錯誤（如WebSocket無法連線）可以考慮在 UI 顯示模態對話框要求使用者重新整理或檢查連線；對於非致命錯誤（如一次聊天請求失敗），使用 toast 簡要提示即可，而 ChatService 可以自動將 `isProcessing` 設為 false 允許使用者重試。確保每個 Service 的錯誤都被攔截並轉化為對應的 UI 行為，不要將未處理的 Exception 泄漏至整個應用。可以在 api.ts 的 `fetchApi` 中攔截常見 HTTP 錯誤碼轉換為易讀訊息，減少各處服務重覆判斷。
7. **性能與資源管理**：隨著功能增多，需要留意前端性能。例如：
    - **三維渲染性能**：Three.js 場景應避免載入過大的模型或過多燈光特效影響效能。已載入的模型可儲存在 service 單例中以便重用，不必每次切換場景都重載。Zustand store 更新也儘量批量處理，減少不必要渲染。
    - **記憶體管理**：AudioService 錄音得到的媒體流與AudioBuffer用完應適時釋放。WebSocket 長連線在應用卸載或使用者登出時應關閉（WebSocketService 應提供清理函式）。
    - **防止記憶體洩漏**：注意**移除監聽**。目前 WebSocketService 提供 `removeHandler`[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=isConnected%2C%20%20%20%20,%2F%2F%20%E7%A7%BB%E9%99%A4%E6%B6%88%E6%81%AF%E8%99%95%E7%90%86%E5%99%A8)方便在元件 unmount 時解除訂閱。同樣，如果有使用 `setInterval` 或 `requestAnimationFrame` 等，也要在適當時機清除。React Three Fiber 的 useFrame 已內建隨元件生命週期管理，一般不需特別清除，但如果手動使用 `THREE.Clock` 等還是要注意。
8. **遵循既有程式風格**：專案程式碼中註解使用了中英文結合，方便理解。建議繼續這種寫法，在修改或新增模組時給出**清晰的註解**說明意圖，尤其是涉及複雜數學計算（如表情插值）或非常規技巧時。變數命名上，保持簡潔具意義的英文命名，同時在註解用中文闡述業務語意，利於團隊不同背景的人交流。
9. **擴充服務時的建議**：README 中已提到擴充服務的步驟[github.com](https://github.com/eggyy1224/space_live_project/tree/main/prototype/frontend/src#:~:text=%E6%93%B4%E5%B1%95%E6%9C%8D%E5%8B%99)。實踐中，若要新增例如「任務Service」或「商品Service」，可參考現有模式：在 `services/` 新建 `<New>Service.ts`，定義類別與 hook，在 `services/index.ts` 匯出。新 service 若需要全域狀態，可在 `store/slices` 加入新 slice 並在 `store/index.ts` 合併[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/store/index.ts#:~:text=%2F%2F%20%E5%90%88%E4%BD%B5%E6%89%80%E6%9C%89%20slice%20%E9%A1%9E%E5%9E%8B%E7%82%BA%E6%9C%80%E7%B5%82%20Store,%E9%A1%9E%E5%9E%8B)[github.com](https://github.com/eggyy1224/space_live_project/blob/main/prototype/frontend/src/store/index.ts#:~:text=devtools)。保持這種模組化擴充方式，可以讓新功能自然地融合進現有架構，而不破壞原有部分。
10. **考慮路由與多頁**：目前應用通過狀態切換視圖，若未來需求變複雜（例如新增一個獨立的「關於我們」頁面或「設定」頁），可以考慮引入 React Router 將應用拆分多路由頁面。屆時可創建 pages 資料夾或類似架構，把現有 ChatRoom 和 LiveRoom 視作不同路由。路由化有助於程式按需加載、在URL反映當前狀態等。但若暫無此需要，繼續保持單頁應用並透過狀態切換即可，畢竟目前兩種模式耦合度高（聊天需要模型表情，即使切頁也可能需要共享模型狀態）。

總而言之，Space Live 前端架構以清晰的分層實現了高度模組化和可讀性。在後續維護中，應秉持「**關注點分離**」和「**單一職責**」原則，不斷梳理清楚資料流，充分利用全域狀態和自訂 Hook 來降低元件複雜度。同時要注意程式健全性，在錯誤處理、性能優化方面持續改進。按照現有的架構風格開發新功能，相信能夠較順利地擴充系統且減少迴歸風險，讓整體專案保持易於理解和維護。