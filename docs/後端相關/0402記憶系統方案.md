# 記憶系統方案設計文檔

## 1. 背景與目標

當前的空間語音交互系統基於 FastAPI 和 LangGraph 對話框架，實現了用戶透過語音與虛擬太空人互動。為了讓虛擬太空人具有「記憶」，能夠記住過去的對話和事件，我們計劃在現有系統中新增一個「記憶系統」模組。

這個記憶系統將使用 SQLAlchemy 連接 PostgreSQL 資料庫，並利用 pgvector 擴展來支援語義向量檢索，從而實現四個方面的長期記憶功能：

1. **任務記錄模組**：記錄虛擬太空人執行的任務內容、完成時間及結果。
2. **互動片段儲存模組**：保存每次語音互動的文字轉錄內容，並將其轉換為向量存入向量索引，用於後續語義檢索對話歷史。
3. **情緒狀態追蹤模組**：追蹤太空人在每次對話或重要事件後的情緒/心情分數，記錄情緒隨時間的變化。
4. **自我認知模組**：保存太空人的人物設定和個性資料（例如出生地、喜好、技能、性格特質等），作為虛擬太空人的長期自我記憶。

新增的記憶系統需要無縫整合進現有的 LangGraph 對話流程，使虛擬太空人在對話中能夠查詢和更新這些記憶。

## 2. 系統架構概覽

整合記憶模組後的系統技術架構如下：

現有系統由 FastAPI 服務（承載 LangGraph 對話代理）以及語音識別(STT)/語音合成(TTS)模組構成。我們將在此架構中引入一個持久化的記憶資料庫和相應的記憶管理模組。FastAPI 後端將透過 SQLAlchemy 連接到 PostgreSQL 資料庫，用於儲存和檢索虛擬太空人的記憶資料。資料庫啟用 pgvector 擴展以支援向量化的語義搜尋，使系統能夠根據語義相似度檢索過往對話片段和人物設定等資訊。

在更新後的架構中，當用戶與太空人對話時，FastAPI 應用會同時處理與 LangGraph 智能體的交互以及對記憶資料庫的讀寫。LangGraph 對話框架負責生成太空人的回應，而記憶模組則在對話流程的關鍵節點提供支持：
- 將新的對話內容寫入資料庫
- 在生成回覆前從資料庫中提取相關記憶供 LangGraph 使用

## 3. 項目結構與文件放置

為了實現上述功能，需要在 backend 後端程式碼中增加相應的模組和文件。建議的項目結構調整如下：

### 資料庫模型文件
在 `backend/` 目錄下新增一個子目錄（例如命名為 `models/`）用於存放資料庫 ORM 模型定義。可以創建一個文件如 `backend/models/memory_models.py`（或按模組拆分多個文件），其中定義任務、互動片段、情緒和自我認知這幾個記憶相關的 ORM 類。

### 記憶模組邏輯
在 `backend/` 目錄下新增記憶管理模組文件，例如 `backend/memory_module.py` 或建立一個 `memory/` 包。其中編寫封裝記憶操作的程式碼，包括插入新記憶、查詢歷史記憶等函數。這個模組將被 FastAPI 路由或 LangGraph 流程調用。在該模組中，可以實現一個類（如 `MemoryManager`）或一組方法，用於與資料庫交互讀寫記憶。

### 資料庫初始化
在後端啟動時（例如 FastAPI 應用啟動事件）初始化資料庫連接。可以創建一個 `backend/db.py` 用於配置 SQLAlchemy engine 和 Session 會話。透過讀取配置（如 `.env` 環境變數中的資料庫 URL），創建連接到 PostgreSQL 的引擎，並確保已載入 pgvector 擴展（第一次運行時需要在資料庫中執行 `CREATE EXTENSION vector;`）。模型類可以繼承 SQLAlchemy 的 Base，並透過 `Base.metadata.create_all(engine)`（或使用 Alembic 遷移）在資料庫中創建相應的表。

### 整合到 FastAPI
FastAPI 的路由處理函數（尤其是處理語音輸入/輸出的部分）需要引入記憶模組。例如，在接收用戶語音輸入並轉換成文字後，調用記憶模組的函數將轉錄文字儲存到資料庫；在生成回覆前，調用記憶查詢函數獲取相關記憶並傳遞給 LangGraph 的代理。相應地，還需要在任務完成或情緒更新時調用記憶模組。確保在這些地方導入並使用了 `memory_module.py` 中的邏輯。

透過以上組織，我們將新的記憶系統程式碼與現有程式碼結構解耦，保證程式碼清晰：ORM 定義集中在 models，記憶操作封裝在 memory_module，主應用邏輯則調用這些模組。

## 4. 資料庫設計與 ORM 模型

記憶系統的四個子模組將映射為四張資料庫表，對應四個 ORM 模型類。下面列出每個模型的主要字段設計和關係：

### TaskLog（任務記錄）
存儲每個任務的信息。

| 字段 | 類型 | 說明 |
|------|------|------|
| id | 主鍵ID | 自動生成的唯一識別碼 |
| description | Text | 任務內容描述，例如"修復太陽能板" |
| completed_at | DateTime | 完成時間 |
| result | Text | 任務結果/狀態，例如"成功"或"失敗"，也可擴展為枚舉類型 |
| remarks | Text | (可選)備註或詳細結果說明 |

**用途**：記錄所有虛擬太空人執行過的任務。當任務完成時插入一條記錄。日後可按時間或名稱查詢任務，甚至透過語義搜尋任務描述來回顧相關任務（如用戶問"之前做過哪些修理？"）。

### InteractionMemory（互動片段）
存儲每次用戶與太空人的對話片段（主要是用戶發言部分）。

| 字段 | 類型 | 說明 |
|------|------|------|
| id | 主鍵ID | 自動生成的唯一識別碼 |
| timestamp | DateTime | 對話發生時間 |
| speaker | String | 說話方標識（如"user"表示用戶；如果也存儲機器人回覆則可用"assistant"區分） |
| content | Text | 對話內容文字，例如用戶語音轉錄後的文字 |
| embedding | Vector | 內容的語義嵌入向量（例如1536維浮點向量），此字段依賴pgvector擴展，用於語義相似度搜尋 |

**用途**：持久化保存對話歷史。每當用戶透過 STT 得到文字輸入後，系統將創建一條 InteractionMemory 記錄並計算其向量嵌入存入資料庫。後續在生成回覆時，可以對比新問題與歷史片段的向量相似度，從中檢索出相關的對話片段作為參考。

**注意**：當前設計主要存儲用戶的發言，如有需要也可以存儲太空人的回答，以完整記錄整輪對話歷史。

### EmotionState（情緒狀態）
追蹤虛擬太空人的情緒變化。

| 字段 | 類型 | 說明 |
|------|------|------|
| id | 主鍵ID | 自動生成的唯一識別碼 |
| timestamp | DateTime | 記錄時間 |
| mood_score | Integer或Float | 心情/情緒分數，可以約定一個範圍，例如0-100表示從非常消沉到非常高興，或-1.0-1.0的情感極性分值 |
| cause_interaction_id | 外鍵 | 引用引起此次情緒變化的互動片段（InteractionMemory.id）。可為空(null)表示情緒變化源自其他事件（如任務結果） |
| notes | Text | (可選)情緒原因描述，例如"任務成功，士氣提升"或"受到用戶批評，情緒下降" |

**用途**：每次對話或事件後記錄太空人的情緒值。例如用戶說話內容積極時提高分數，消極時降低分數；或者任務失敗導致情緒降低。通過累積的 EmotionState，可以追蹤太空人的心理曲線，並在對話中查詢當前情緒以調整回應語氣（例如如果 mood_score 很低，太空人的回答可能顯得沮喪）。

### SelfProfile（自我認知/人物檔案）
保存虛擬太空人的設定資料。

| 字段 | 類型 | 說明 |
|------|------|------|
| id | 主鍵ID | 自動生成的唯一識別碼 |
| key | Text | 屬性鍵或類別，例如"name"、"birthplace"、"skill"、"personality"等 |
| value | Text | 具體的屬性內容描述，可以是一句話或一段話。例如key=birthplace時，value="我出生於月球基地Alpha。" |
| embedding | Vector | value文字的語義向量表示。對每條人物信息計算嵌入，以支持語義查詢 |

**用途**：存儲太空人的基本身份和人格信息。每條記錄代表角色的一個方面。透過對這些描述的向量搜尋，系統能夠在用戶問及相關信息時檢索答案。例如，當用戶問"你從哪裡來"時，會將問題向量與 SelfProfile 表中嵌入向量匹配，找到 birthplace 條目並據此回答。

這些 ORM 模型透過 SQLAlchemy 定義，並與 PostgreSQL 中的表結構對應。對於使用了向量的字段（如 InteractionMemory.embedding 和 SelfProfile.embedding），需確保資料庫已安裝 pgvector 擴展，並在模型中使用相應的向量類型（可以借助 sqlalchemy_pgvector 等庫定義 Vector 類型）。此外，可以為這些向量列創建索引（如 IVF 或 HNSW 索引），以加速語義搜尋查詢。

**模型關係**：目前設計假定系統中只有一個虛擬太空人角色，因此各表不需要角色ID關聯，都屬於同一角色。EmotionState 通過 cause_interaction_id 與某次對話相關聯，方便追溯引發情緒變化的用戶言論。如果未來支持多角色或多用戶，可在上述表中加入角色/會話標識用於隔離不同主體的記憶。

## 5. 記憶模組設計

### 5.1 任務記錄模組

任務記錄模組負責將虛擬太空人執行的任務情況保存到資料庫中。每當太空人完成一項任務或行動（例如完成某項維修、收集樣本等），系統會調用該模組在 TaskLog 表中創建一條新記錄，記錄任務描述、完成時間以及結果。

任務記錄模組提供接口函數（例如 `MemoryManager.log_task(description, result)`）供對話流程調用：當 LangGraph 代理確定任務結束或收到任務執行結果時，調用此接口寫入日誌。後續在需要總結或查詢任務履歷時，可以透過查詢 TaskLog 來獲取歷史任務列表。

例如，如果用戶詢問"上次完成任務的結果如何？"，系統可以檢索 TaskLog 中最近的任務記錄，並將結果提供給 LangGraph 生成回答。這確保虛擬太空人能夠回憶自己執行過的任務以及成果，在對話中具備"經歷"的累積。

### 5.2 互動片段儲存模組

互動片段儲存模組負責記錄每輪對話中用戶說的話（以及可選地太空人的回覆）作為長期對話記憶。

具體實現上，在用戶每次語音輸入經過 STT 轉換成文字後，系統會調用該模組將文字內容保存為新的 InteractionMemory 記錄，並計算其語義嵌入向量儲存到向量索引中。這一步保證了對話內容被持久化保存，同時通過向量表示支持後續的語義搜尋。

例如，用戶之前某次說"氧氣供應狀態如何？"，系統將該句儲存並向量化。如果稍後用戶提及"氧氣"相關的話題，系統可以在生成回答前查詢向量資料庫，找到與"氧氣"相關的過往對話片段，提醒虛擬太空人之前已經討論過的內容。

在 LangGraph 對話流程中，互動儲存模組的調用通常發生在用戶輸入階段和生成回覆之前：

1. 用戶每說一句話，先調用 `MemoryManager.store_interaction(user_text)` 將其保存
2. 在 LangGraph 準備回覆時，調用 `MemoryManager.query_interactions(query_text)` 對比當前查詢與歷史對話，返回相似的幾個片段內容

這些片段可以作為額外上下文傳遞給語言模型，提升回答的連貫性和正確性。互動片段儲存模組相當於對話的長期記憶庫，使虛擬太空人即使經過多輪交流也能"想起"之前用戶說過的話。

### 5.3 情緒狀態追蹤模組

情緒追蹤模組用於記錄虛擬太空人在對話過程中的情緒起伏，使其具有情感上的連續性。每當發生用戶對話或任務事件後，系統會評估太空人的情緒變化，通過接口（例如 `MemoryManager.update_mood(score, cause)`) 寫入 EmotionState 表。

情緒的評估可以基於簡單規則或模型：例如對用戶語句進行情感分析（positive 提高分數，negative 降低分數），或者根據任務結果調整（任務成功提升情緒，失敗降低情緒）。記錄的 mood_score 數值反映太空人當下的心情狀態。

情緒記錄模組在 LangGraph 流程中的更新點包括：

1. 用戶每次發言後，先根據內容更新一次情緒（例如用戶鼓勵太空人則心情上升，責備則下降）
2. 任務完成後，根據結果再次調整情緒

每次更新都會往 EmotionState 表添加一條新記錄，保留時間序列歷史。這樣一來，虛擬太空人具有簡單的"情感記憶"。當用戶問"你現在感覺怎麼樣？"時，系統可以查找 EmotionState 最新的記錄，將當前情緒值翻譯成口語描述（如"我覺得有點沮喪"）供 LangGraph 參考生成回覆。

此外，LangGraph 代理在生成回答時也可讀取當前情緒分數，調整回覆的語氣和內容，使太空人的個性更加真實可信。

### 5.4 自我認知模組

自我認知模組為虛擬太空人提供關於自身的長期記憶，包括背景故事、個人愛好和特長等。該模組通過 SelfProfile 表保存多條角色設定記錄，每條記錄描述太空人的一個方面。

系統在初始化時會預先將這些人物檔案載入到資料庫：可以在應用啟動時運行腳本或程式碼插入預定義的 key-value 資料（如姓名、出生地、專業技能等），並計算好嵌入向量。這些初始記憶可以來源於設計文檔或配置文件，載入後即駐留在資料庫中，供對話階段查詢。

自我認知模組的查詢接口（例如 `MemoryManager.query_profile(question)`）會接收用戶的問題內容，將其向量化後在 SelfProfile 向量索引中尋找相似度最高的條目。例如用戶問"你的興趣是什麼？"系統會檢索與"興趣"相關的條目（比如"我喜歡天文學和園藝"），然後將該信息提供給 LangGraph 作為答案依據。

如果用戶直接問一些涉及人設的問題（如"你是哪年出生的？"），系統也可以直接匹配對應的 Profile 項並給出答案。除了被動問答，自我認知模組也讓太空人在對話中保持一致的人設——LangGraph 代理可以在每次對話開始時載入這些 Profile 信息作為系統提示的一部分（例如包含太空人的自我介紹或個性說明），確保生成的回覆符合既定的人格特質。

通過自我認知模組，虛擬太空人擁有一套靜態的自我知識庫，相當於大腦中的"自傳"。無論對話進行多久，這些關於自我的記憶都會長期保留，可隨時檢索，使太空人的言行與其背景設定保持一致。

## 6. 對話流程中的記憶整合

引入記憶系統後的語音交互流程如下。

用戶與虛擬太空人對話時的流程，記憶模組在其中插入的時機和作用。在整個對話循環中，系統按以下順序執行各步驟，其中加粗部分為與記憶模組交互的關鍵節點：

1. **用戶語音輸入**：用戶通過麥克風說出一句話，進入系統的語音輸入通道。

2. **語音轉文字 (STT)**：使用語音識別服務將用戶的語音轉換為文字字串。

3. **存儲互動片段**：一旦獲得用戶文字，立即調用互動儲存模組，將該文字內容保存為新的 InteractionMemory 記錄，並生成其語義向量存入資料庫索引。這一步為後續可能的查詢做好準備。

4. **更新情緒狀態**：緊接著，根據用戶話語內容調用情緒追蹤模組計算虛擬太空人的情緒變化，並寫入 EmotionState。例如，如果用戶語氣友好，則提高 mood_score；如果言辭衝突，則降低 mood_score。

5. **準備上下文記憶**：在生成回覆之前，系統從記憶資料庫中檢索與當前對話相關的記憶信息：
   - 調用互動儲存模組的查詢功能，將當前用戶提問轉換為向量，與歷史 InteractionMemory 向量比較，找出相似度最高的若干對話片段（例如最近提及相關話題的發言）。
   - 查詢任務記錄模組，如用戶問題涉及過去的任務（例如提到某次行動的結果），則檢索 TaskLog 中符合條件的記錄（可以根據任務名稱關鍵詞或時間過濾）。
   - 查詢自我認知模組，如用戶提問涉及太空人自身信息，則檢索 SelfProfile 獲取相應的檔案內容。

   系統將以上檢索到的相關記憶片段匯總形成上下文信息（可以是若干句文字），供下一步對話生成使用。

6. **LangGraph 智能體生成回覆**：FastAPI 後端將用戶當前的問題文字以及上一步準備的記憶上下文一起傳遞給 LangGraph 對話代理（LLM Agent）。通常這可以通過構造一個包含記憶內容的系統消息或在 prompt 中加入"記憶"部分來實現。LangGraph（基於大語言模型）據此生成虛擬太空人的回答文字。在回答過程中，代理能夠"看到"提供的記憶片段，從而避免自相矛盾，並能夠引用之前發生的事件或提供更符合角色背景的回答。

7. **任務執行與記錄**：如果 LangGraph 代理在回覆過程中需要執行某個任務（例如通過工具調用完成某動作）或在回覆中表示完成了某項任務，則相應的業務邏輯會執行該任務。執行完畢後，調用任務記錄模組將該任務記錄寫入 TaskLog，以持久保存其結果。這一步確保任何明確完成的任務都會進入任務日誌。例如，如果太空人在對話中報告"我已經修好了設備"，系統應在 TaskLog 中添加"修理設備"任務完成的記錄。

8. **（可選）更新情緒狀態**：根據第7步任務的結果，再次調整 EmotionState（例如任務成功讓情緒好轉，任務失敗則情緒下降），並記錄這次變化。

9. **文字轉語音 (TTS)**：將 LangGraph 生成的回覆文字通過語音合成轉換為語音，由揚聲器播放給用戶。

10. **循環下一輪**：本輪對話完成，系統等待用戶的下一次語音輸入，新的一輪交互按相同步驟進行，期間記憶資料庫持續累積更多記錄。

在上述流程中，記憶系統的查詢和更新被緊密地嵌入對話循環，使虛擬太空人具備了"短期+長期記憶"的能力：既能記住對話上下文，又能憶及更久之前的事件和自身背景。例如，當對話進行到第10輪時，系統已保存了前9輪用戶的所有話語和多個情緒狀態、可能的任務記錄，LangGraph 生成回覆時仍然可以檢索到在第1輪時用戶曾提過的一個要求，表現出良好的上下文連貫性。

通過這種方式，FastAPI + LangGraph 的語音對話系統成功整合了長時記憶功能。虛擬太空人不僅能夠根據用戶當前提問作答，還能參考"過去經歷"和"自身設定"來提供更準確且個性化的回應。這套記憶系統採用標準的 ORM 和向量資料庫技術實現，易於維護和擴展。例如，可以進一步豐富自我認知資料，或調整情緒模型以塑造不同性格的虛擬角色。在保證現有即時語音交互性能的同時，虛擬太空人將具備更類似人類的對話持續性和記憶力。